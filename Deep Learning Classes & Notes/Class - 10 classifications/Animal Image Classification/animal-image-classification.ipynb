{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27073d05",
   "metadata": {
    "id": "0HMohYnDxIrZ",
    "papermill": {
     "duration": 0.014582,
     "end_time": "2024-12-03T18:35:42.798911",
     "exception": false,
     "start_time": "2024-12-03T18:35:42.784329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://media.licdn.com/dms/image/v2/D5612AQGOui8XZUZJSA/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1680532048475?e=2147483647&v=beta&t=5gZVHYNL2Vc2mK3iKrpK-FcpURIFdyaP4Vi38eeeZyM\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55835240",
   "metadata": {
    "id": "nE2iCKCZxIri",
    "papermill": {
     "duration": 0.011849,
     "end_time": "2024-12-03T18:35:42.822891",
     "exception": false,
     "start_time": "2024-12-03T18:35:42.811042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20240105124903/Mutliclass-Classification-vs-multilabel-classification-(1).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb34e7d",
   "metadata": {
    "id": "ZBoMe2x3xIrk",
    "papermill": {
     "duration": 0.011698,
     "end_time": "2024-12-03T18:35:42.846551",
     "exception": false,
     "start_time": "2024-12-03T18:35:42.834853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> <center>Animal Classification Project:</center></h1>\n",
    "\n",
    "#### 1. **Define Project Goal**: Classify images into Cat, Dog, and Horse categories.  \n",
    "#### 2. **Setup Environment**: Install necessary libraries (TensorFlow, Keras, etc.) and organize project folders.  \n",
    "#### 3. **Load Dataset**: Download and inspect the dataset structure.  \n",
    "#### 4. **Preprocess Images**: Resize, normalize, and augment images to improve model generalization.  \n",
    "#### 5. **Split Dataset**: Separate images into train, validation, and test sets.  \n",
    "#### 6. **Design CNN Model**: Build a Convolutional Neural Network architecture for feature extraction and classification.  \n",
    "#### 7. **Compile Model**: Choose optimizer (Adam), loss function (categorical cross-entropy), and evaluation metrics (accuracy).  \n",
    "#### 8. **Train Model**: Fit the model using the training data and validate it using the validation set.  \n",
    "#### 9. **Evaluate Model**: Test the model on unseen data to calculate accuracy and other metrics.  \n",
    "#### 10. **Optimize Performance**: Adjust hyperparameters, use dropout, or fine-tune layers for better accuracy.  \n",
    "#### 11. **Save Model**: Save the trained model in HDF5 format for future use.  \n",
    "#### 12. **Build Prediction Pipeline**: Create a function to preprocess new images and make predictions.  \n",
    "#### 13. **Develop Deployment App**: Build a web app using Streamlit or Flask for users to upload and classify images.  \n",
    "#### 14. **Test Deployment**: Validate the app with various image inputs to ensure functionality.  \n",
    "#### 15. **Document & Present**: Prepare a report with project details, results, and upload code to a repository (e.g., GitHub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d08833a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:35:42.872058Z",
     "iopub.status.busy": "2024-12-03T18:35:42.871319Z",
     "iopub.status.idle": "2024-12-03T18:35:54.764528Z",
     "shell.execute_reply": "2024-12-03T18:35:54.763826Z"
    },
    "id": "Y4IFZalPxIrm",
    "papermill": {
     "duration": 11.908014,
     "end_time": "2024-12-03T18:35:54.766485",
     "exception": false,
     "start_time": "2024-12-03T18:35:42.858471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746e732",
   "metadata": {
    "id": "AlFRz9k2xIrp",
    "papermill": {
     "duration": 0.011821,
     "end_time": "2024-12-03T18:35:54.790819",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.778998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. **Define Project Goal**: Classify images into Cat, Dog, and Horse categories.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3fa65",
   "metadata": {
    "id": "01QC0b4TxIrq",
    "papermill": {
     "duration": 0.011637,
     "end_time": "2024-12-03T18:35:54.814292",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.802655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Input Representation:**\n",
    "   - Each input image is denoted as:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;\\mathbf{X}&space;\\in&space;\\mathbb{R}^{h&space;\\times&space;w&space;\\times&space;c}\" title=\" \\mathbf{X} \\in \\mathbb{R}^{h \\times w \\times c}\" />\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;h\" title=\" h\" />: Image height.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;w\" title=\" w\" />: Image width.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;c\" title=\" c\" />: Number of color channels (e.g., <img src=\"https://latex.codecogs.com/svg.image?&space;c&space;=&space;3\" title=\" c = 3\" /> for RGB).\n",
    "\n",
    "---\n",
    "\n",
    "2. **Output Representation:**\n",
    "   - The output is a probability vector representing the likelihood of the image belonging to each of the three classes:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;\\mathbf{y}&space;=&space;\\begin{bmatrix}&space;p(C_1)&space;\\\\&space;p(C_2)&space;\\\\&space;p(C_3)&space;\\end{bmatrix}\" title=\" \\mathbf{y} = \\begin{bmatrix} p(C_1) \\\\ p(C_2) \\\\ p(C_3) \\end{bmatrix}\" />\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;p(C_1)\" title=\" p(C_1)\" />: Probability of the image being a Cat.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;p(C_2)\" title=\" p(C_2)\" />: Probability of the image being a Dog.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;p(C_3)\" title=\" p(C_3)\" />: Probability of the image being a Horse.\n",
    "   - These probabilities satisfy:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;\\sum_{i=1}^{3}&space;p(C_i)&space;=&space;1\" title=\" \\sum_{i=1}^{3} p(C_i) = 1\" />\n",
    "\n",
    "---\n",
    "\n",
    "3. **Classification Function:**\n",
    "   - We use a function <img src=\"https://latex.codecogs.com/svg.image?&space;f\" title=\" f\" /> parameterized by model weights <img src=\"https://latex.codecogs.com/svg.image?&space;\\Theta\" title=\" \\Theta\" /> to map input images to the output probabilities:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;f(\\mathbf{X};&space;\\Theta)&space;=&space;\\mathbf{y}\" title=\" f(\\mathbf{X}; \\Theta) = \\mathbf{y}\" />\n",
    "   - Here, <img src=\"https://latex.codecogs.com/svg.image?&space;\\Theta\" title=\" \\Theta\" /> includes the weights and biases of the neural network.\n",
    "\n",
    "---\n",
    "\n",
    "4. **Prediction Rule:**\n",
    "   - The predicted class <img src=\"https://latex.codecogs.com/svg.image?&space;\\hat{C}\" title=\" \\hat{C}\" /> is determined by selecting the class with the highest probability:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;\\hat{C}&space;=&space;\\text{argmax}_{i}&space;\\,p(C_i)\" title=\" \\hat{C} = \\text{argmax}_{i} \\,p(C_i)\" />\n",
    "\n",
    "---\n",
    "\n",
    "5. **Loss Function:**\n",
    "   - During training, we minimize the categorical cross-entropy loss:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;L&space;=&space;-\\frac{1}{N}\\sum_{i=1}^{N}&space;\\sum_{j=1}^{3}&space;y_{i,j}&space;\\log&space;\\hat{y}_{i,j}\" title=\" L = -\\frac{1}{N}\\sum_{i=1}^{N} \\sum_{j=1}^{3} y_{i,j} \\log \\hat{y}_{i,j}\" />\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;N\" title=\" N\" />: Number of training samples.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;y_{i,j}\" title=\" y_{i,j}\" />: True label for sample <img src=\"https://latex.codecogs.com/svg.image?&space;i\" title=\" i\" /> and class <img src=\"https://latex.codecogs.com/svg.image?&space;j\" title=\" j\" /> (1 if true, 0 otherwise).\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;\\hat{y}_{i,j}\" title=\" \\hat{y}_{i,j}\" />: Predicted probability for sample <img src=\"https://latex.codecogs.com/svg.image?&space;i\" title=\" i\" /> and class <img src=\"https://latex.codecogs.com/svg.image?&space;j\" title=\" j\" />.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c9a42",
   "metadata": {
    "id": "b_XvDemYxIrr",
    "papermill": {
     "duration": 0.011522,
     "end_time": "2024-12-03T18:35:54.837532",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.826010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. **Setup Environment**: Install necessary libraries (TensorFlow, Keras, etc.) and organize project folders.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7b98d",
   "metadata": {
    "id": "X3hRI7kFxIrs",
    "papermill": {
     "duration": 0.011608,
     "end_time": "2024-12-03T18:35:54.860889",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.849281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Setup Environment for Kaggle**\n",
    "\n",
    "If youâ€™re working on Kaggle, the setup is streamlined as many libraries are pre-installed. Below are the steps to prepare your environment:\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Verify Pre-Installed Libraries**\n",
    "Kaggle already includes libraries like TensorFlow, Keras, NumPy, Matplotlib, and Pandas. To check their versions:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Install Additional Libraries (If Needed)**\n",
    "If specific libraries like `opencv-python`, `plotly`, or `streamlit` are required, use the Kaggle notebookâ€™s terminal or code cells to install them:\n",
    "```python\n",
    "!pip install opencv-python plotly\n",
    "```\n",
    "\n",
    "For deployment tools like Streamlit, you can install it but deployment isnâ€™t applicable directly in Kaggle.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Organize Dataset**\n",
    "Kaggle datasets are available in the `/kaggle/input/` directory. Organize your dataset for training, validation, and testing:\n",
    "- Use a directory structure like this:\n",
    "  ```\n",
    "  /kaggle/input/dataset/\n",
    "  â”œâ”€â”€ train/\n",
    "  â”‚   â”œâ”€â”€ cat/\n",
    "  â”‚   â”œâ”€â”€ dog/\n",
    "  â”‚   â””â”€â”€ horse/\n",
    "  â”œâ”€â”€ val/\n",
    "  â”‚   â”œâ”€â”€ cat/\n",
    "  â”‚   â”œâ”€â”€ dog/\n",
    "  â”‚   â””â”€â”€ horse/\n",
    "  â””â”€â”€ test/\n",
    "      â”œâ”€â”€ cat/\n",
    "      â”œâ”€â”€ dog/\n",
    "      â””â”€â”€ horse/\n",
    "  ```\n",
    "- Use Kaggleâ€™s file path for loading datasets:\n",
    "  ```python\n",
    "  train_dir = \"/kaggle/input/dataset/train\"\n",
    "  val_dir = \"/kaggle/input/dataset/val\"\n",
    "  test_dir = \"/kaggle/input/dataset/test\"\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Prepare Folders for Outputs**\n",
    "Since you cannot create folders in Kaggleâ€™s input directory, save outputs like models and results in `/kaggle/working/`:\n",
    "```bash\n",
    "/kaggle/working/\n",
    "â”œâ”€â”€ models/       # For saving trained models\n",
    "â”œâ”€â”€ results/      # For storing evaluation metrics or plots\n",
    "```\n",
    "\n",
    "Create folders in code if needed:\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.makedirs(\"/kaggle/working/models\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/results\", exist_ok=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Use Kaggle GPU**\n",
    "Enable GPU in the Kaggle notebook for faster training:\n",
    "- Go to **Settings** -> **Accelerator** -> Select **GPU**.\n",
    "\n",
    "Verify GPU access:\n",
    "```python\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Notebook Structure**\n",
    "Split your Kaggle notebook into the following sections:\n",
    "1. **Data Exploration**: Load and visualize the dataset.\n",
    "2. **Preprocessing**: Resize, normalize, and augment images.\n",
    "3. **Model Building**: Define the CNN architecture.\n",
    "4. **Training**: Train the model with TensorFlow/Keras.\n",
    "5. **Evaluation**: Test the model and visualize results.\n",
    "6. **Save Outputs**: Save the trained model and plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14070795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:35:54.885816Z",
     "iopub.status.busy": "2024-12-03T18:35:54.885358Z",
     "iopub.status.idle": "2024-12-03T18:35:54.889282Z",
     "shell.execute_reply": "2024-12-03T18:35:54.888628Z"
    },
    "id": "-yezdBldxIru",
    "papermill": {
     "duration": 0.018136,
     "end_time": "2024-12-03T18:35:54.890761",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.872625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/kaggle/working/models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27291b3f",
   "metadata": {
    "id": "dEaECCWTxIrv",
    "papermill": {
     "duration": 0.011769,
     "end_time": "2024-12-03T18:35:54.914361",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.902592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. **Load Dataset**: Download and inspect the dataset structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b3f10",
   "metadata": {
    "id": "QeIvf7wvxIrw",
    "papermill": {
     "duration": 0.011488,
     "end_time": "2024-12-03T18:35:54.937660",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.926172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1. Download the Dataset**\n",
    "- If the dataset is from Kaggle's Datasets section, add it to your notebook from the **Data** tab.\n",
    "- The dataset will appear in `/kaggle/input/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537555d4",
   "metadata": {
    "id": "ameW9pc_xIrw",
    "papermill": {
     "duration": 0.011578,
     "end_time": "2024-12-03T18:35:54.960954",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.949376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **2. Define Dataset Paths**\n",
    "Set the paths to the dataset directories:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be22d8ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:35:54.985921Z",
     "iopub.status.busy": "2024-12-03T18:35:54.985249Z",
     "iopub.status.idle": "2024-12-03T18:35:54.989090Z",
     "shell.execute_reply": "2024-12-03T18:35:54.988318Z"
    },
    "id": "CdBtUweQxIrx",
    "papermill": {
     "duration": 0.017947,
     "end_time": "2024-12-03T18:35:54.990677",
     "exception": false,
     "start_time": "2024-12-03T18:35:54.972730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/input/animal/Dataset/train\"\n",
    "val_dir = \"/kaggle/input/animal/Dataset/val\"\n",
    "test_dir = \"/kaggle/input/animal/Dataset/test\"\n",
    "\n",
    "# Define image dimensions and batch size\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c289802",
   "metadata": {
    "id": "Wt2f-S7IxIry",
    "papermill": {
     "duration": 0.011935,
     "end_time": "2024-12-03T18:35:55.014602",
     "exception": false,
     "start_time": "2024-12-03T18:35:55.002667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **3. Inspect Dataset Structure**\n",
    "List the dataset structure to ensure all files are correctly organized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e057a772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:35:55.039593Z",
     "iopub.status.busy": "2024-12-03T18:35:55.039350Z",
     "iopub.status.idle": "2024-12-03T18:35:55.473009Z",
     "shell.execute_reply": "2024-12-03T18:35:55.471873Z"
    },
    "id": "g0XXlkkTxIry",
    "outputId": "b0ba03cf-f27d-419a-c2dd-eed94db4d1ee",
    "papermill": {
     "duration": 0.447584,
     "end_time": "2024-12-03T18:35:55.474472",
     "exception": true,
     "start_time": "2024-12-03T18:35:55.026888",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/animal/Dataset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# List the directories\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Categories:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Categories:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mlistdir(val_dir))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Categories:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mlistdir(test_dir))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/animal/Dataset/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the directories\n",
    "print(\"Train Categories:\", os.listdir(train_dir))\n",
    "print(\"Validation Categories:\", os.listdir(val_dir))\n",
    "print(\"Test Categories:\", os.listdir(test_dir))\n",
    "\n",
    "# Example: Inspect a specific category (e.g., 'cat')\n",
    "cat_train_samples = os.listdir(os.path.join(train_dir, \"cat\"))\n",
    "print(f\"Number of cat images in training set: {len(cat_train_samples)}\")\n",
    "dog_train_samples = os.listdir(os.path.join(train_dir, \"dog\"))\n",
    "print(f\"Number of dog images in training set: {len(dog_train_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56059390",
   "metadata": {
    "id": "txMehmyRxIr1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **4. Count Images in Each Split**\n",
    "Create a helper function to count the number of images in each category:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16be98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:24.490190Z",
     "iopub.status.busy": "2024-12-03T12:16:24.489924Z",
     "iopub.status.idle": "2024-12-03T12:16:24.503582Z",
     "shell.execute_reply": "2024-12-03T12:16:24.502908Z",
     "shell.execute_reply.started": "2024-12-03T12:16:24.490165Z"
    },
    "id": "CWW7Jl8HxIr1",
    "outputId": "26736fe1-e8b6-4131-fe20-6c682012cdbc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List the directories\n",
    "print(\"Train Categories:\", os.listdir(train_dir))\n",
    "print(\"Validation Categories:\", os.listdir(val_dir))\n",
    "print(\"Test Categories:\", os.listdir(test_dir))\n",
    "\n",
    "# Example: Inspect a specific category (e.g., 'cat')\n",
    "cat_train_samples = os.listdir(os.path.join(train_dir, \"cat\"))\n",
    "print(f\"Number of cat images in training set: {len(cat_train_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0de683",
   "metadata": {
    "id": "n2wSRD_yxIr2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **5. Visualize Sample Images**\n",
    "Plot a few sample images from each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a5371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T14:58:09.407774Z",
     "iopub.status.busy": "2024-12-03T14:58:09.407451Z",
     "iopub.status.idle": "2024-12-03T14:58:09.636023Z",
     "shell.execute_reply": "2024-12-03T14:58:09.635155Z",
     "shell.execute_reply.started": "2024-12-03T14:58:09.407746Z"
    },
    "id": "wu6MpwbrxIr3",
    "outputId": "fe13af2e-9d60-4390-8ac5-e73bbdff02fb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_images_in_directory(directory):\n",
    "    categories = os.listdir(directory)\n",
    "    counts = {category: len(os.listdir(os.path.join(directory, category))) for category in categories}\n",
    "    return counts\n",
    "\n",
    "# Count images\n",
    "train_counts = count_images_in_directory(train_dir)\n",
    "val_counts = count_images_in_directory(val_dir)\n",
    "test_counts = count_images_in_directory(test_dir)\n",
    "\n",
    "print(\"Training Set Image Counts:\", train_counts)\n",
    "print(\"Validation Set Image Counts:\", val_counts)\n",
    "print(\"Test Set Image Counts:\", test_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ebb1b7",
   "metadata": {
    "id": "-gXWRGP5xIr4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **6. Check Image Dimensions**\n",
    "Ensure the images have consistent dimensions or resize them later:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88686c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:39:15.861983Z",
     "iopub.status.busy": "2024-12-03T15:39:15.861290Z",
     "iopub.status.idle": "2024-12-03T15:39:15.865479Z",
     "shell.execute_reply": "2024-12-03T15:39:15.864554Z",
     "shell.execute_reply.started": "2024-12-03T15:39:15.861952Z"
    },
    "id": "71aZ9hj5xIr4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# directory = \"/kaggle/input/animal/Dataset/train/cat/016646b99e465837f6ce07c5720ea256f15057f22f8b1fb686db51eafa3558c3437f970_1920.jpg\"\n",
    "# img=  Image.open(directory)\n",
    "# img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:42:47.034552Z",
     "iopub.status.busy": "2024-12-03T15:42:47.034239Z",
     "iopub.status.idle": "2024-12-03T15:42:47.099878Z",
     "shell.execute_reply": "2024-12-03T15:42:47.099173Z",
     "shell.execute_reply.started": "2024-12-03T15:42:47.034525Z"
    },
    "id": "vbOaf8ldxIr5",
    "outputId": "f8a4fdd5-9157-44b3-fb93-6f948869545b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def inspect_image_dimensions(directory, category):\n",
    "    sample_image_path = os.path.join(directory, category, os.listdir(os.path.join(directory, category))[1])\n",
    "    print(sample_image_path)\n",
    "    with Image.open(sample_image_path) as img:\n",
    "        print(f\"Sample image dimensions for {category}: {img.size}\")\n",
    "\n",
    "inspect_image_dimensions(train_dir, \"cat\")\n",
    "inspect_image_dimensions(train_dir, \"dog\")\n",
    "inspect_image_dimensions(train_dir, \"horse\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fe74c",
   "metadata": {
    "id": "s1J_LQAExIr6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 4. **Preprocess Images**: Resize, normalize, and augment images to improve model generalization.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0301067",
   "metadata": {
    "id": "F9URlvoAxIr7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **1. Resize Images**\n",
    "- Each image is resized to a fixed dimension <img src=\"https://latex.codecogs.com/svg.image?&space;h&space;\\times&space;w\" title=\" h \\times w\" />, ensuring consistency across the dataset:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}'&space;\\in&space;\\mathbb{R}^{h&space;\\times&space;w&space;\\times&space;c}\" title=\" \\mathbf{X}' \\in \\mathbb{R}^{h \\times w \\times c}\" />\n",
    "  Where:\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;h\" title=\" h\" />: Target height.\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;w\" title=\" w\" />: Target width.\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;c\" title=\" c\" />: Number of channels (e.g., 3 for RGB images).\n",
    "\n",
    "Resizing operation is mathematically defined as:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}'(i,j)&space;=&space;\\mathbf{X}(\\alpha&space;i,&space;\\alpha&space;j)\" title=\" \\mathbf{X}'(i,j) = \\mathbf{X}(\\alpha i, \\alpha j)\" />  \n",
    "  Where:\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;\\alpha&space;=&space;\\frac{h_\\text{orig}}{h}\" title=\" \\alpha = \\frac{h_\\text{orig}}{h}\" /> and <img src=\"https://latex.codecogs.com/svg.image?&space;\\frac{w_\\text{orig}}{w}\" title=\" \\frac{w_\\text{orig}}{w}\" /> are scaling factors.\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;(i,j)\" title=\" (i,j)\" /> denotes pixel coordinates in the resized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bce4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:46:09.580496Z",
     "iopub.status.busy": "2024-12-03T15:46:09.579640Z",
     "iopub.status.idle": "2024-12-03T15:46:20.788513Z",
     "shell.execute_reply": "2024-12-03T15:46:20.787762Z",
     "shell.execute_reply.started": "2024-12-03T15:46:09.580462Z"
    },
    "id": "K9pR3MZTxIr7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e12ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:49:05.983866Z",
     "iopub.status.busy": "2024-12-03T15:49:05.983423Z",
     "iopub.status.idle": "2024-12-03T15:49:06.015244Z",
     "shell.execute_reply": "2024-12-03T15:49:06.014417Z",
     "shell.execute_reply.started": "2024-12-03T15:49:05.983833Z"
    },
    "id": "CIjMnTNaxIr9",
    "outputId": "b2be8bcb-4517-49f5-a2dd-a9d913b89acc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    return tf.image.resize(image, target_size)\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "directory = \"/kaggle/input/animal/Dataset/train/cat/016646b99e465837f6ce07c5720ea256f15057f22f8b1fb686db51eafa3558c3437f970_1920.jpg\"\n",
    "img=  Image.open(directory)\n",
    "print(img.size)\n",
    "\n",
    "resize_image(img, target_size = (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b219ae",
   "metadata": {
    "id": "3IJj506GxIr-",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **2. Normalize Pixel Values**\n",
    "- Normalize the pixel values of each image <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}\" title=\" \\mathbf{X}\" /> to scale between 0 and 1:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{norm}&space;=&space;\\frac{\\mathbf{X}}{255}\" title=\" \\mathbf{X}_\\text{norm} = \\frac{\\mathbf{X}}{255}\" />\n",
    "  Where:\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;\\mathbf{X}\" title=\" \\mathbf{X}\" />: Original pixel value (0 to 255).\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;\\mathbf{X}_\\text{norm}\" title=\" \\mathbf{X}_\\text{norm}\" />: Normalized pixel value (0 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedab8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:53:16.520577Z",
     "iopub.status.busy": "2024-12-03T15:53:16.519821Z",
     "iopub.status.idle": "2024-12-03T15:53:16.559683Z",
     "shell.execute_reply": "2024-12-03T15:53:16.558871Z",
     "shell.execute_reply.started": "2024-12-03T15:53:16.520539Z"
    },
    "id": "g4JotpaqxIr_",
    "outputId": "d3b95927-f6de-4a45-b739-e812eb2c8948",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return image / 255.0\n",
    "\n",
    "print(\"-----------\")\n",
    "print(resize_image(img, target_size = (2, 2)))\n",
    "print(\"-----------\")\n",
    "print(normalize_image(resize_image(img, target_size = (2, 2))))\n",
    "print(\"-----------\")\n",
    "print(min(normalize_image(resize_image(img, target_size = (2, 2)))[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb16e1",
   "metadata": {
    "id": "I54yXxDsxIsA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **3. Standardize Images (Optional)**\n",
    "- If needed, standardize images to have zero mean and unit variance:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{std}&space;=&space;\\frac{\\mathbf{X}_\\text{norm}&space;-&space;\\mu}{\\sigma}\" title=\" \\mathbf{X}_\\text{std} = \\frac{\\mathbf{X}_\\text{norm} - \\mu}{\\sigma}\" />\n",
    "  Where:\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;\\mu\" title=\" \\mu\" />: Mean of pixel values.\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?&space;\\sigma\" title=\" \\sigma\" />: Standard deviation of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8199c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T15:58:05.019970Z",
     "iopub.status.busy": "2024-12-03T15:58:05.019180Z",
     "iopub.status.idle": "2024-12-03T15:58:05.588708Z",
     "shell.execute_reply": "2024-12-03T15:58:05.587848Z",
     "shell.execute_reply.started": "2024-12-03T15:58:05.019937Z"
    },
    "id": "MIuAI5KdxIsA",
    "outputId": "37db69b7-c348-4e43-a711-f0acd44537dd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to standardize an image\n",
    "def standardize_image(image):\n",
    "    mean, std = tf.math.reduce_mean(image), tf.math.reduce_std(image)\n",
    "    return (image - mean) / std\n",
    "\n",
    "# Example usage\n",
    "standardized_image = standardize_image(normalize_image(resize_image(img, target_size = (2, 2))))\n",
    "print(\"Standardized image mean:\", tf.reduce_mean(standardized_image).numpy())\n",
    "print(\"Standardized image std:\", tf.math.reduce_std(standardized_image).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861fe58",
   "metadata": {
    "id": "TD7fwe0nxIsC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **4. Augment Images**\n",
    "Augmentation introduces variability into the dataset by applying transformations. Mathematically:\n",
    "\n",
    "1. **Rotation:**\n",
    "   Rotate each image by an angle <img src=\"https://latex.codecogs.com/svg.image?\\theta\" title=\" \\theta\" /> (e.g., random between <img src=\"https://latex.codecogs.com/svg.image?&space;[-30^\\circ,&space;30^\\circ]\" title=\" [-30^\\circ, 30^\\circ]\" />):\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{rot}(x',&space;y')&space;=&space;\\mathbf{X}(\\cos\\theta&space;x&space;-&space;\\sin\\theta&space;y,&space;\\sin\\theta&space;x&space;&plus;&space;\\cos\\theta&space;y)\" title=\" \\mathbf{X}_\\text{rot}(x', y') = \\mathbf{X}(\\cos\\theta x - \\sin\\theta y, \\sin\\theta x + \\cos\\theta y)\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91540847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T16:17:47.042306Z",
     "iopub.status.busy": "2024-12-03T16:17:47.041954Z",
     "iopub.status.idle": "2024-12-03T16:17:47.694043Z",
     "shell.execute_reply": "2024-12-03T16:17:47.693167Z",
     "shell.execute_reply.started": "2024-12-03T16:17:47.042277Z"
    },
    "id": "xxurDfxHxIsD",
    "outputId": "e7a69333-6284-4957-d7f7-083c6383fed0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotate_image(image, max_angle=180):\n",
    "    radians = tf.random.uniform([], -max_angle, max_angle) * (3.141592653589793 / 180.0)  # Convert to radians\n",
    "    print(\"Radients\", radians)\n",
    "    print(\"---------------------\")\n",
    "    return tf.image.rot90(image, tf.cast(radians / 1.5708, tf.int32))\n",
    "print(\"------------------\")\n",
    "directory = \"/kaggle/input/animal/Dataset/train/cat/016646b99e465837f6ce07c5720ea256f15057f22f8b1fb686db51eafa3558c3437f970_1920.jpg\"\n",
    "img= plt.imread(directory)\n",
    "print(\"Image\", img)\n",
    "print(\"------------------\")\n",
    "\n",
    "image = rotate_image(img, max_angle = 360)\n",
    "print(\"New Image\", image)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6024a2",
   "metadata": {
    "id": "OmmfrNclxIsE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "2. **Scaling:**\n",
    "   Resize the image by a scale factor <img src=\"https://latex.codecogs.com/svg.image?s\" title=\" s\" />:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{scaled}(x',&space;y')&space;=&space;\\mathbf{X}(s&space;x,&space;s&space;y)\" title=\" \\mathbf{X}_\\text{scaled}(x', y') = \\mathbf{X}(s x, s y)\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdd09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T16:20:23.060688Z",
     "iopub.status.busy": "2024-12-03T16:20:23.059813Z",
     "iopub.status.idle": "2024-12-03T16:20:23.065445Z",
     "shell.execute_reply": "2024-12-03T16:20:23.064479Z",
     "shell.execute_reply.started": "2024-12-03T16:20:23.060650Z"
    },
    "id": "41_0JIwdxIsF",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_image(image, scale_range=(0.8, 1.2)):\n",
    "    scale_factor = tf.random.uniform([], scale_range[0], scale_range[1])\n",
    "    original_shape = tf.cast(tf.shape(image)[:2], tf.float32)\n",
    "    new_size = tf.cast(scale_factor * original_shape, tf.int32)\n",
    "    return tf.image.resize(image, new_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b539850",
   "metadata": {
    "id": "BSz81fvcxIsG",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "3. **Flipping:**\n",
    "   Horizontally flip the image:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{flip}(x,&space;y)&space;=&space;\\mathbf{X}(-x,&space;y)\" title=\" \\mathbf{X}_\\text{flip}(x, y) = \\mathbf{X}(-x, y)\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebf2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:24.820337Z",
     "iopub.status.busy": "2024-12-03T12:16:24.820074Z",
     "iopub.status.idle": "2024-12-03T12:16:24.829423Z",
     "shell.execute_reply": "2024-12-03T12:16:24.828672Z",
     "shell.execute_reply.started": "2024-12-03T12:16:24.820305Z"
    },
    "id": "ccuyawmIxIsH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Flip the image horizontally\n",
    "# flipped_image = tf.image.flip_left_right(resize_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101b25f",
   "metadata": {
    "id": "vWZeeCxoxIsH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "4. **Shearing:**\n",
    "   Apply shearing transformation:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{shear}(x',&space;y')&space;=&space;\\mathbf{X}(x&space;&plus;&space;\\lambda&space;y,&space;y)\" title=\" \\mathbf{X}_\\text{shear}(x', y') = \\mathbf{X}(x + \\lambda y, y)\" />\n",
    "   Where:\n",
    "   - <img src=\"https://latex.codecogs.com/svg.image?\\lambda\" title=\" \\lambda\" />: Shear factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759d2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T16:24:38.515084Z",
     "iopub.status.busy": "2024-12-03T16:24:38.514715Z",
     "iopub.status.idle": "2024-12-03T16:24:38.523074Z",
     "shell.execute_reply": "2024-12-03T16:24:38.522166Z",
     "shell.execute_reply.started": "2024-12-03T16:24:38.515051Z"
    },
    "id": "2XUq_LulxIsI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shear_image(image, shear=0.2):\n",
    "    # Create the shear matrix\n",
    "    image_shape = tf.shape(image)\n",
    "    height, width = tf.cast(image_shape[0], tf.float32), tf.cast(image_shape[1], tf.float32)\n",
    "    shear_matrix = tf.convert_to_tensor([\n",
    "        [1.0, shear, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ], dtype=tf.float32)\n",
    "    inverse_shear_matrix = tf.linalg.inv(shear_matrix)\n",
    "\n",
    "    # Generate grid of pixel coordinates\n",
    "    x_coords, y_coords = tf.meshgrid(tf.range(width), tf.range(height))\n",
    "    ones = tf.ones_like(x_coords, dtype=tf.float32)\n",
    "    homogeneous_coords = tf.stack([tf.cast(x_coords, tf.float32), tf.cast(y_coords, tf.float32), ones], axis=-1)\n",
    "    homogeneous_coords = tf.reshape(homogeneous_coords, (-1, 3))\n",
    "    transformed_coords = tf.matmul(homogeneous_coords, tf.transpose(inverse_shear_matrix))\n",
    "    transformed_coords = tf.reshape(transformed_coords, (height, width, 3))\n",
    "\n",
    "    x_transformed = tf.clip_by_value(transformed_coords[..., 0], 0, width - 1)\n",
    "    y_transformed = tf.clip_by_value(transformed_coords[..., 1], 0, height - 1)\n",
    "    return tf.gather_nd(image, tf.stack([tf.cast(y_transformed, tf.int32), tf.cast(x_transformed, tf.int32)], axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051b761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T16:26:23.177382Z",
     "iopub.status.busy": "2024-12-03T16:26:23.176629Z",
     "iopub.status.idle": "2024-12-03T16:26:23.899100Z",
     "shell.execute_reply": "2024-12-03T16:26:23.898126Z",
     "shell.execute_reply.started": "2024-12-03T16:26:23.177344Z"
    },
    "id": "dBoHcPKmxIsJ",
    "outputId": "d5b70155-64a8-4553-d882-ea19b0bce4f4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/input/animal/Dataset/train/cat/016646b99e465837f6ce07c5720ea256f15057f22f8b1fb686db51eafa3558c3437f970_1920.jpg\"\n",
    "img= plt.imread(directory)\n",
    "plt.imshow(img)\n",
    "#print(\"Image\", img)\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4681df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T16:26:51.627740Z",
     "iopub.status.busy": "2024-12-03T16:26:51.627416Z",
     "iopub.status.idle": "2024-12-03T16:26:52.319910Z",
     "shell.execute_reply": "2024-12-03T16:26:52.319132Z",
     "shell.execute_reply.started": "2024-12-03T16:26:51.627715Z"
    },
    "id": "w3K-BkboxIsa",
    "outputId": "72df70ac-fae3-4143-f1b0-134afc38728e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = shear_image(img, shear=0.8)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f9604",
   "metadata": {
    "id": "P7p05p_jxIsc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **5. Final Preprocessed Image**\n",
    "After applying all transformations, the preprocessed image can be denoted as:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}_\\text{final}&space;=&space;f_\\text{aug}(\\mathbf{X}_\\text{std})\" title=\" \\mathbf{X}_\\text{final} = f_\\text{aug}(\\mathbf{X}_\\text{std})\" />\n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?f_\\text{aug}\" title=\" f_\\text{aug}\" /> represents the augmentation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f85897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:24.840820Z",
     "iopub.status.busy": "2024-12-03T12:16:24.840483Z",
     "iopub.status.idle": "2024-12-03T12:16:27.908797Z",
     "shell.execute_reply": "2024-12-03T12:16:27.907980Z",
     "shell.execute_reply.started": "2024-12-03T12:16:24.840776Z"
    },
    "id": "2ZdeAiR3xIsc",
    "outputId": "498bd177-0479-46a1-cad1-66291f389183",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "def preprocess_image(image, label):\n",
    "    # Resize\n",
    "    image = resize_image(image)\n",
    "    # Normalize\n",
    "    image = normalize_image(image)\n",
    "    # Data Augmentation\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = rotate_image(image)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "# Load Dataset\n",
    "def load_dataset(data_dir):\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "# Load train, validation, and test datasets\n",
    "train_dataset = load_dataset(train_dir)\n",
    "val_dataset = load_dataset(val_dir)\n",
    "test_dataset = load_dataset(test_dir)\n",
    "\n",
    "# Apply preprocessing pipeline\n",
    "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(preprocess_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(preprocess_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Print Dataset Info\n",
    "print(f\"Train Dataset: {train_dataset}\")\n",
    "print(f\"Validation Dataset: {val_dataset}\")\n",
    "print(f\"Test Dataset: {test_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b5b7c",
   "metadata": {
    "id": "oEpPnOxKxIsd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 5. **Split Dataset**: Separate images into train, validation, and test sets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93330e4c",
   "metadata": {
    "id": "1U23t3J7xIse",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Mathematical Representation**\n",
    "\n",
    "1. **Dataset Size**:\n",
    "   - Let the total number of images in the dataset be denoted as:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;N\" title=\" N\" />\n",
    "\n",
    "2. **Splitting Ratios**:\n",
    "   - Define the proportions for each subset:\n",
    "     - Training set: <img src=\"https://latex.codecogs.com/svg.image?&space;r_\\text{train}\" title=\" r_\\text{train}\" />\n",
    "     - Validation set: <img src=\"https://latex.codecogs.com/svg.image?&space;r_\\text{val}\" title=\" r_\\text{val}\" />\n",
    "     - Test set: <img src=\"https://latex.codecogs.com/svg.image?&space;r_\\text{test}\" title=\" r_\\text{test}\" />\n",
    "   - These ratios satisfy:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?&space;r_\\text{train}&space;&plus;&space;r_\\text{val}&space;&plus;&space;r_\\text{test}&space;=&space;1\" title=\" r_\\text{train} + r_\\text{val} + r_\\text{test} = 1\" />\n",
    "\n",
    "3. **Number of Images in Each Subset**:\n",
    "   - Calculate the number of images for each subset:\n",
    "     - Training: <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{train}&space;=&space;r_\\text{train}&space;\\cdot&space;N\" title=\" N_\\text{train} = r_\\text{train} \\cdot N\" />\n",
    "     - Validation: <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{val}&space;=&space;r_\\text{val}&space;\\cdot&space;N\" title=\" N_\\text{val} = r_\\text{val} \\cdot N\" />\n",
    "     - Test: <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{test}&space;=&space;r_\\text{test}&space;\\cdot&space;N\" title=\" N_\\text{test} = r_\\text{test} \\cdot N\" />\n",
    "\n",
    "4. **Randomization**:\n",
    "   - Shuffle the dataset indices to ensure a random split.\n",
    "\n",
    "5. **Index Assignment**:\n",
    "   - Assign indices to each subset:\n",
    "     - Training indices: <img src=\"https://latex.codecogs.com/svg.image?&space;I_\\text{train}&space;=&space;\\{1,&space;\\dots,&space;N_\\text{train}\\}\" title=\" I_\\text{train} = \\{1, \\dots, N_\\text{train}\\}\" />\n",
    "     - Validation indices: <img src=\"https://latex.codecogs.com/svg.image?&space;I_\\text{val}&space;=&space;\\{N_\\text{train}&plus;1,&space;\\dots,&space;N_\\text{train}&plus;N_\\text{val}\\}\" title=\" I_\\text{val} = \\{N_\\text{train}+1, \\dots, N_\\text{train}+N_\\text{val}\\}\" />\n",
    "     - Test indices: <img src=\"https://latex.codecogs.com/svg.image?&space;I_\\text{test}&space;=&space;\\{N_\\text{train}&plus;N_\\text{val}&plus;1,&space;\\dots,&space;N\\}\" title=\" I_\\text{test} = \\{N_\\text{train}+N_\\text{val}+1, \\dots, N\\}\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90efa8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:27.910360Z",
     "iopub.status.busy": "2024-12-03T12:16:27.909980Z",
     "iopub.status.idle": "2024-12-03T12:16:27.915591Z",
     "shell.execute_reply": "2024-12-03T12:16:27.914701Z",
     "shell.execute_reply.started": "2024-12-03T12:16:27.910322Z"
    },
    "id": "uCXYeRbrxIse",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# # Paths to the original dataset and target directories\n",
    "# original_dataset_dir = \"/kaggle/input/animal/Dataset/\"\n",
    "# train_dir = \"Dataset_Split/train\"\n",
    "# val_dir = \"Dataset_Split/val\"\n",
    "# test_dir = \"Dataset_Split/test\"\n",
    "\n",
    "# # Define split ratios\n",
    "# r_train, r_val, r_test = 0.7, 0.2, 0.1  # Train: 70%, Val: 20%, Test: 10%\n",
    "# assert r_train + r_val + r_test == 1, \"The split ratios must sum to 1.\"\n",
    "\n",
    "# # Create directories for splits\n",
    "# for split_dir in [train_dir, val_dir, test_dir]:\n",
    "#     for category in [\"cat\", \"dog\", \"horse\"]:\n",
    "#         os.makedirs(os.path.join(split_dir, category), exist_ok=True)\n",
    "\n",
    "# # Function to split dataset\n",
    "# def split_dataset(original_dir, train_dir, val_dir, test_dir, r_train, r_val, r_test):\n",
    "#     for category in os.listdir(original_dir):\n",
    "#         category_path = os.path.join(original_dir, category)\n",
    "#         images = os.listdir(category_path)\n",
    "#         N = len(images)  # Total number of images\n",
    "\n",
    "#         # Shuffle image filenames\n",
    "#         random.shuffle(images)\n",
    "\n",
    "#         # Calculate split sizes\n",
    "#         N_train = int(r_train * N)\n",
    "#         N_val = int(r_val * N)\n",
    "#         N_test = N - N_train - N_val\n",
    "\n",
    "#         # Split images into train, val, test\n",
    "#         train_images = images[:N_train]\n",
    "#         val_images = images[N_train:N_train + N_val]\n",
    "#         test_images = images[N_train + N_val:]\n",
    "\n",
    "#         # Copy files to corresponding directories\n",
    "#         for img in train_images:\n",
    "#             shutil.copy(os.path.join(category_path, img), os.path.join(train_dir, category))\n",
    "#         for img in val_images:\n",
    "#             shutil.copy(os.path.join(category_path, img), os.path.join(val_dir, category))\n",
    "#         for img in test_images:\n",
    "#             shutil.copy(os.path.join(category_path, img), os.path.join(test_dir, category))\n",
    "\n",
    "# # Apply the function\n",
    "# split_dataset(original_dataset_dir, train_dir, val_dir, test_dir, r_train, r_val, r_test)\n",
    "\n",
    "# print(\"Dataset split complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549dffab",
   "metadata": {
    "id": "CdcMcBG-xIsf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. **Input Parameters**:\n",
    "   - The `original_dataset_dir` contains the original dataset structured by category.\n",
    "   - The `train_dir`, `val_dir`, and `test_dir` directories are created for storing the split datasets.\n",
    "\n",
    "2. **Randomization**:\n",
    "   - The `random.shuffle` function ensures images are randomly assigned to subsets.\n",
    "\n",
    "3. **Split Sizes**:\n",
    "   - The sizes of the splits are computed using the formulas:\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{train}&space;=&space;r_\\text{train}&space;\\cdot&space;N\" title=\" N_\\text{train} = r_\\text{train} \\cdot N\" />\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{val}&space;=&space;r_\\text{val}&space;\\cdot&space;N\" title=\" N_\\text{val} = r_\\text{val} \\cdot N\" />\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?&space;N_\\text{test}&space;=&space;r_\\text{test}&space;\\cdot&space;N\" title=\" N_\\text{test} = r_\\text{test} \\cdot N\" />\n",
    "\n",
    "4. **File Copying**:\n",
    "   - Images are copied into their respective split directories using `shutil.copy`.\n",
    "\n",
    "5. **Output**:\n",
    "   - The dataset is split into `train`, `val`, and `test` directories, each containing subdirectories for categories (e.g., `cat`, `dog`, `horse`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3a33b",
   "metadata": {
    "id": "b9_lYuhAxIsg",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 6. **Design CNN Model**: Build a Convolutional Neural Network architecture for feature extraction and classification.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ecfd1",
   "metadata": {
    "id": "oo9fgm8pxIsh",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Mathematical Representation**\n",
    "\n",
    "#### **1. Input Image Tensor**\n",
    "Each input image is represented as a 3D tensor:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}&space;\\in&space;\\mathbb{R}^{h&space;\\times&space;w&space;\\times&space;c}\" title=\" \\mathbf{X} \\in \\mathbb{R}^{h \\times w \\times c}\" />  \n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?&space;h\" title=\" h\" />: Image height (e.g., 224 pixels).\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?&space;w\" title=\" w\" />: Image width (e.g., 224 pixels).\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?&space;c\" title=\" c\" />: Number of channels (3 for RGB).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Convolutional Layers**\n",
    "The convolutional layer applies a filter (kernel) <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{K}&space;\\in&space;\\mathbb{R}^{k&space;\\times&space;k&space;\\times&space;c}\" title=\" \\mathbf{K} \\in \\mathbb{R}^{k \\times k \\times c}\" /> to extract features:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?&space;\\mathbf{X}'(i,j)&space;=&space;\\sum_{m=0}^{k-1}&space;\\sum_{n=0}^{k-1}&space;\\mathbf{X}(i&plus;m,&space;j&plus;n)&space;\\cdot&space;\\mathbf{K}(m,n)\" title=\" \\mathbf{X}'(i,j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\mathbf{X}(i+m, j+n) \\cdot \\mathbf{K}(m,n)\" />  \n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?k\" title=\" k\" />: Kernel size.\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}'\" title=\" \\mathbf{X}'\" />: Output feature map.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Activation Function**\n",
    "ReLU (Rectified Linear Unit) is applied element-wise to introduce non-linearity:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?f(x)&space;=&space;\\max(0,&space;x)\" title=\" f(x) = \\max(0, x)\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Pooling Layer**\n",
    "Pooling reduces the spatial dimensions of the feature map. For max pooling:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}''(i,j)&space;=&space;\\max_{m,n}&space;\\mathbf{X}'(2i&plus;m,&space;2j&plus;n)\" title=\" \\mathbf{X}''(i,j) = \\max_{m,n} \\mathbf{X}'(2i+m, 2j+n)\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Fully Connected Layer**\n",
    "The flattened feature map is passed through a dense layer:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?z_k&space;=&space;\\sum_{i=1}^{d}w_{k,i}x_i&space;&plus;&space;b_k\" title=\" z_k = \\sum_{i=1}^{d}w_{k,i}x_i + b_k\" />  \n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?d\" title=\" d\" />: Input dimension.\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?w_{k,i}\" title=\" w_{k,i}\" />: Weights.\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?b_k\" title=\" b_k\" />: Bias.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. SoftMax Output**\n",
    "The output probabilities for each class are computed using SoftMax:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?p(C_k)&space;=&space;\\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" title=\" p(C_k) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" />  \n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?p(C_k)\" title=\" p(C_k)\" />: Probability of class <img src=\"https://latex.codecogs.com/svg.image?C_k\" title=\" C_k\" />.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cc746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:27.916923Z",
     "iopub.status.busy": "2024-12-03T12:16:27.916608Z",
     "iopub.status.idle": "2024-12-03T12:16:28.025754Z",
     "shell.execute_reply": "2024-12-03T12:16:28.024914Z",
     "shell.execute_reply.started": "2024-12-03T12:16:27.916893Z"
    },
    "id": "o2KA1UoMxIsi",
    "outputId": "d1939204-0bcf-49bb-ae73-2c96c7519251",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN architecture\n",
    "def build_cnn_model(input_shape=(224, 224, 3), num_classes=3):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Convolutional Layer 3\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "cnn_model = build_cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add12219",
   "metadata": {
    "id": "pxcbbmvoxIsj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. **Input Layer**:\n",
    "   - Input shape is set to <img src=\"https://latex.codecogs.com/svg.image?224&space;\\times&space;224&space;\\times&space;3\" title=\"224 \\times 224 \\times 3\" /> (height, width, channels).\n",
    "\n",
    "2. **Convolutional Layers**:\n",
    "   - Three convolutional layers with increasing filter sizes (32, 64, 128) are used.\n",
    "   - Each convolutional layer is followed by max pooling to reduce dimensions.\n",
    "\n",
    "3. **Fully Connected Layers**:\n",
    "   - A dense layer with 128 neurons learns high-level features.\n",
    "   - The final layer has 3 neurons (one for each class: Cat, Dog, Horse) with a SoftMax activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2267a52",
   "metadata": {
    "id": "1wklGf8PxIsk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 7. **Compile Model**: Choose optimizer (Adam), loss function (categorical cross-entropy), and evaluation metrics (accuracy).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ccdb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:28.027172Z",
     "iopub.status.busy": "2024-12-03T12:16:28.026823Z",
     "iopub.status.idle": "2024-12-03T12:16:28.054999Z",
     "shell.execute_reply": "2024-12-03T12:16:28.054224Z",
     "shell.execute_reply.started": "2024-12-03T12:16:28.027134Z"
    },
    "id": "WgiNFXvxxIsl",
    "outputId": "07178f70-2995-461b-808a-fe67e499baee",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71673af",
   "metadata": {
    "id": "Y-YFiQfgxIsl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Compilation**:\n",
    "   - Optimizer: Adam\n",
    "   - Loss: Sparse categorical crossentropy (used for integer labels)\n",
    "   - Metrics: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6b0c0",
   "metadata": {
    "id": "Tdchl9rexIsm",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 8. **Train Model**: Fit the model using the training data and validate it using the validation set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91651d0",
   "metadata": {
    "id": "ioNbfNJqxIsn",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Mathematical Representation**\n",
    "\n",
    "1. **Forward Pass**:\n",
    "   For each input image <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}\" title=\" \\mathbf{X}\" /> in the training set:\n",
    "   - Compute the output (logits) from the model:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{z}&space;=&space;f(\\mathbf{X};&space;\\Theta)\" title=\" \\mathbf{z} = f(\\mathbf{X}; \\Theta)\" />  \n",
    "     Where:\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?f(\\mathbf{X};&space;\\Theta)\" title=\" f(\\mathbf{X}; \\Theta)\" />: Model function.\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?\\Theta\" title=\" \\Theta\" />: Model parameters (weights and biases).\n",
    "\n",
    "   - Apply the SoftMax function to compute class probabilities:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?p(C_k|&space;\\mathbf{X})&space;=&space;\\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" title=\" p(C_k| \\mathbf{X}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" />  \n",
    "     Where:\n",
    "     - <img src=\"https://latex.codecogs.com/svg.image?p(C_k|&space;\\mathbf{X})\" title=\" p(C_k| \\mathbf{X})\" />: Probability of class <img src=\"https://latex.codecogs.com/svg.image?C_k\" title=\" C_k\" />.\n",
    "\n",
    "\n",
    "\n",
    "2. **Loss Function**:\n",
    "   Use the categorical cross-entropy loss for multi-class classification:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?L&space;=&space;-\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=1}^{3}y_{i,k}&space;\\cdot&space;\\log&space;p(C_k|&space;\\mathbf{X}_i)\" title=\" L = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=1}^{3}y_{i,k} \\cdot \\log p(C_k| \\mathbf{X}_i)\" />  \n",
    "   Where:\n",
    "   - <img src=\"https://latex.codecogs.com/svg.image?N\" title=\" N\" />: Number of training samples.\n",
    "   - <img src=\"https://latex.codecogs.com/svg.image?y_{i,k}\" title=\" y_{i,k}\" />: One-hot encoded label for the <img src=\"https://latex.codecogs.com/svg.image?i\" title=\" i\" />-th sample and class <img src=\"https://latex.codecogs.com/svg.image?k\" title=\" k\" />.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Backpropagation**:\n",
    "   Gradients of the loss with respect to model parameters are computed:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\frac{\\partial&space;L}{\\partial&space;\\Theta}\" title=\" \\frac{\\partial L}{\\partial \\Theta}\" />  \n",
    "   These gradients are used to update the parameters using an optimizer, such as Adam.\n",
    "\n",
    "---\n",
    "\n",
    "4. **Validation**:\n",
    "   During validation, calculate accuracy:\n",
    "   <img src=\"https://latex.codecogs.com/svg.image?\\text{Accuracy}&space;=&space;\\frac{\\text{Number&space;of&space;Correct&space;Predictions}}{\\text{Total&space;Number&space;of&space;Samples}}\" title=\" \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Samples}}\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d7792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:28.056234Z",
     "iopub.status.busy": "2024-12-03T12:16:28.055965Z",
     "iopub.status.idle": "2024-12-03T12:16:28.744642Z",
     "shell.execute_reply": "2024-12-03T12:16:28.743796Z",
     "shell.execute_reply.started": "2024-12-03T12:16:28.056211Z"
    },
    "id": "HTIw9uE4xIso",
    "outputId": "ccb87c93-4d59-4ad2-9012-a67e05013eea",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "def load_dataset(data_dir):\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "# Load train, validation, and test datasets\n",
    "train_dataset = load_dataset(train_dir)\n",
    "val_dataset = load_dataset(val_dir)\n",
    "test_dataset = load_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9866e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:16:28.746085Z",
     "iopub.status.busy": "2024-12-03T12:16:28.745791Z",
     "iopub.status.idle": "2024-12-03T12:17:37.923367Z",
     "shell.execute_reply": "2024-12-03T12:17:37.922651Z",
     "shell.execute_reply.started": "2024-12-03T12:16:28.746051Z"
    },
    "id": "lVwg5IEfxIsp",
    "outputId": "1d475d20-650b-4097-f46a-2d720849a575",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Train the CNN model\n",
    "def train_model(model, train_dataset, val_dataset, epochs=10):\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Call the function to train the model\n",
    "history = train_model(cnn_model, train_dataset, val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570cb107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:17:37.924796Z",
     "iopub.status.busy": "2024-12-03T12:17:37.924533Z",
     "iopub.status.idle": "2024-12-03T12:17:38.125679Z",
     "shell.execute_reply": "2024-12-03T12:17:38.124819Z",
     "shell.execute_reply.started": "2024-12-03T12:17:37.924769Z"
    },
    "id": "jr-gySMSxIsq",
    "outputId": "caac663a-96f4-4ddf-bb61-07867279b9cd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d7fca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:17:38.126861Z",
     "iopub.status.busy": "2024-12-03T12:17:38.126639Z",
     "iopub.status.idle": "2024-12-03T12:17:38.295904Z",
     "shell.execute_reply": "2024-12-03T12:17:38.295106Z",
     "shell.execute_reply.started": "2024-12-03T12:17:38.126839Z"
    },
    "id": "BPEC6dfTxIsr",
    "outputId": "cb2d2e96-3d41-4a5c-d32b-4f4918091ca8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_history(history):\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61010960",
   "metadata": {
    "id": "UfFrb5YLxIsr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "1. **Training Process**:\n",
    "   - The model is trained on `train_dataset` and validated on `val_dataset`.\n",
    "   - Loss is computed using the categorical cross-entropy function:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?L&space;=&space;-\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=1}^{3}y_{i,k}&space;\\cdot&space;\\log&space;p(C_k|&space;\\mathbf{X}_i)\" title=\" L = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=1}^{3}y_{i,k} \\cdot \\log p(C_k| \\mathbf{X}_i)\" />\n",
    "\n",
    "2. **Validation**:\n",
    "   - The modelâ€™s performance is evaluated after each epoch on the validation dataset using accuracy:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?\\text{Accuracy}&space;=&space;\\frac{\\text{Number&space;of&space;Correct&space;Predictions}}{\\text{Total&space;Number&space;of&space;Samples}}\" title=\" \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Samples}}\" />\n",
    "\n",
    "3. **History Object**:\n",
    "   - The `history` object contains loss and accuracy metrics for both training and validation, which can be plotted for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e597f8",
   "metadata": {
    "id": "ved2839bxIss",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 9. **Evaluate Model**: Test the model on unseen data to calculate accuracy and other metrics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1f985",
   "metadata": {
    "id": "cmMbJHRcxIst",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **1. Forward Pass for Predictions**\n",
    "For each test sample <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{X}\" title=\" \\mathbf{X}\" /> in the test dataset:\n",
    "- Compute the logits (model output before SoftMax):\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{z}&space;=&space;f(\\mathbf{X};&space;\\Theta)\" title=\" \\mathbf{z} = f(\\mathbf{X}; \\Theta)\" />\n",
    "- Compute probabilities for each class using the SoftMax function:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?p(C_k|&space;\\mathbf{X})&space;=&space;\\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" title=\" p(C_k| \\mathbf{X}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Predicted Class**\n",
    "The predicted class <img src=\"https://latex.codecogs.com/svg.image?\\hat{C}\" title=\" \\hat{C}\" /> is determined by the class with the highest probability:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\hat{C}&space;=&space;\\text{argmax}_{k}\\,p(C_k|&space;\\mathbf{X})\" title=\" \\hat{C} = \\text{argmax}_{k}\\,p(C_k| \\mathbf{X})\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Accuracy**\n",
    "Accuracy is calculated as the fraction of correctly predicted samples:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\text{Accuracy}&space;=&space;\\frac{\\sum_{i=1}^{N}\\mathbb{1}(\\hat{C}_i&space;=&space;C_i)}{N}\" title=\" \\text{Accuracy} = \\frac{\\sum_{i=1}^{N}\\mathbb{1}(\\hat{C}_i = C_i)}{N}\" />  \n",
    "Where:\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?\\mathbb{1}(\\hat{C}_i&space;=&space;C_i)\" title=\" \\mathbb{1}(\\hat{C}_i = C_i)\" /> is an indicator function that equals 1 if the predicted class <img src=\"https://latex.codecogs.com/svg.image?\\hat{C}_i\" title=\" \\hat{C}_i\" /> matches the true class <img src=\"https://latex.codecogs.com/svg.image?C_i\" title=\" C_i\" /> and 0 otherwise.\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?N\" title=\" N\" /> is the total number of test samples.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Precision, Recall, and F1-Score**\n",
    "For a specific class <img src=\"https://latex.codecogs.com/svg.image?C_k\" title=\" C_k\" />:\n",
    "- **Precision**:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\text{Precision}&space;=&space;\\frac{\\text{True&space;Positives}}{\\text{True&space;Positives}&space;&plus;&space;\\text{False&space;Positives}}\" title=\" \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\" />\n",
    "- **Recall**:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\text{Recall}&space;=&space;\\frac{\\text{True&space;Positives}}{\\text{True&space;Positives}&space;&plus;&space;\\text{False&space;Negatives}}\" title=\" \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\" />\n",
    "- **F1-Score**:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\text{F1-Score}&space;=&space;\\frac{2&space;\\cdot&space;\\text{Precision}&space;\\cdot&space;\\text{Recall}}{\\text{Precision}&space;&plus;&space;\\text{Recall}}\" title=\" \\text{F1-Score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853a727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:17:38.297282Z",
     "iopub.status.busy": "2024-12-03T12:17:38.296944Z",
     "iopub.status.idle": "2024-12-03T12:17:41.326817Z",
     "shell.execute_reply": "2024-12-03T12:17:41.325988Z",
     "shell.execute_reply.started": "2024-12-03T12:17:38.297246Z"
    },
    "id": "7meb_SMLxIst",
    "outputId": "856f6bb8-91df-4188-9070-f093ac45a37b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "# Evaluate the model on the test dataset\n",
    "def evaluate_model(model, test_dataset):\n",
    "    # Get predictions and true labels\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in test_dataset:\n",
    "        predictions = model.predict(images)  # Get probabilities\n",
    "        predicted_classes = np.argmax(predictions, axis=1)  # Get predicted class\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted_classes)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Detailed metrics\n",
    "    report = classification_report(y_true, y_pred, target_names=['Cat', 'Dog', 'Horse'])\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Call the function to evaluate the model\n",
    "evaluate_model(cnn_model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd1333",
   "metadata": {
    "id": "YBUKZn2ZxIsu",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. **Predictions**:\n",
    "   - For each batch of images, the model computes class probabilities using the SoftMax function:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?p(C_k|&space;\\mathbf{X})&space;=&space;\\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" title=\" p(C_k| \\mathbf{X}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{3}\\exp(z_j)}\" />\n",
    "   - The predicted class <img src=\"https://latex.codecogs.com/svg.image?\\hat{C}\" title=\" \\hat{C}\" /> is the one with the highest probability.\n",
    "\n",
    "2. **Metrics**:\n",
    "   - **Accuracy**:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?\\text{Accuracy}&space;=&space;\\frac{\\sum_{i=1}^{N}\\mathbb{1}(\\hat{C}_i&space;=&space;C_i)}{N}\" title=\" \\text{Accuracy} = \\frac{\\sum_{i=1}^{N}\\mathbb{1}(\\hat{C}_i = C_i)}{N}\" />\n",
    "   - **Precision, Recall, F1-Score**:\n",
    "     Calculated using `classification_report`.\n",
    "\n",
    "3. **Output**:\n",
    "   - Overall accuracy.\n",
    "   - Per-class precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca8d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:22:29.234591Z",
     "iopub.status.busy": "2024-12-03T12:22:29.234224Z",
     "iopub.status.idle": "2024-12-03T12:22:31.227085Z",
     "shell.execute_reply": "2024-12-03T12:22:31.226315Z",
     "shell.execute_reply.started": "2024-12-03T12:22:29.234560Z"
    },
    "id": "qWH-fUPIxIsv",
    "outputId": "513b4848-9553-4f0b-beb0-bd578df25eb4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to evaluate the model and plot the confusion matrix\n",
    "y_true, y_pred = evaluate_model(cnn_model, test_dataset)\n",
    "plot_confusion_matrix(y_true, y_pred, class_names=['Cat', 'Dog', 'Horse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da89ae2",
   "metadata": {
    "id": "o__X8dgjxIsv",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 10. **Optimize Performance**: Adjust hyperparameters, use dropout, or fine-tune layers for better accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051c148",
   "metadata": {
    "id": "0io-Sn0IxIsw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **1. Regularization with Dropout**\n",
    "Dropout helps prevent overfitting by randomly deactivating neurons during training:\n",
    "- For a neuron output <img src=\"https://latex.codecogs.com/svg.image?x_i\" title=\" x_i\" />, apply dropout with probability <img src=\"https://latex.codecogs.com/svg.image?p_\\text{drop}\" title=\" p_\\text{drop}\" />:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\tilde{x}_i&space;=&space;\\begin{cases}0,&space;&\\text{with&space;probability}&space;p_\\text{drop}\\\\&space;\\frac{x_i}{1-p_\\text{drop}},&space;&\\text{otherwise}\\end{cases}\" title=\" \\tilde{x}_i = \\begin{cases}0, & \\text{with probability} p_\\text{drop}\\\\ \\frac{x_i}{1-p_\\text{drop}}, & \\text{otherwise}\\end{cases}\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Learning Rate Adjustment**\n",
    "The learning rate <img src=\"https://latex.codecogs.com/svg.image?\\eta\" title=\" \\eta\" /> controls the step size during gradient descent. Use a scheduler:\n",
    "- Initial learning rate: <img src=\"https://latex.codecogs.com/svg.image?\\eta_0\" title=\" \\eta_0\" />\n",
    "- Decay factor: <img src=\"https://latex.codecogs.com/svg.image?\\gamma\" title=\" \\gamma\" />\n",
    "- Updated learning rate at epoch <img src=\"https://latex.codecogs.com/svg.image?t\" title=\" t\" />:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\eta_t&space;=&space;\\eta_0&space;\\cdot&space;\\gamma^t\" title=\" \\eta_t = \\eta_0 \\cdot \\gamma^t\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Transfer Learning**\n",
    "Fine-tune a pre-trained model by updating only the top layers:\n",
    "- For parameters <img src=\"https://latex.codecogs.com/svg.image?\\Theta_\\text{pre}\" title=\" \\Theta_\\text{pre}\" /> from a pre-trained model, keep them fixed:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\frac{\\partial&space;L}{\\partial&space;\\Theta_\\text{pre}}&space;=&space;0\" title=\" \\frac{\\partial L}{\\partial \\Theta_\\text{pre}} = 0\" />\n",
    "- Update only new parameters <img src=\"https://latex.codecogs.com/svg.image?\\Theta_\\text{new}\" title=\" \\Theta_\\text{new}\" />:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\Theta_\\text{new}&space;\\leftarrow&space;\\Theta_\\text{new}&space;-&space;\\eta&space;\\cdot&space;\\frac{\\partial&space;L}{\\partial&space;\\Theta_\\text{new}}\" title=\" \\Theta_\\text{new} \\leftarrow \\Theta_\\text{new} - \\eta \\cdot \\frac{\\partial L}{\\partial \\Theta_\\text{new}}\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Batch Normalization**\n",
    "Batch normalization normalizes intermediate activations to improve training stability:\n",
    "- For a batch of activations <img src=\"https://latex.codecogs.com/svg.image?\\mathbf{A}\" title=\" \\mathbf{A}\" />:\n",
    "  <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\mathbf{A}}&space;=&space;\\frac{\\mathbf{A}-\\mu}{\\sigma}\" title=\" \\hat{\\mathbf{A}} = \\frac{\\mathbf{A}-\\mu}{\\sigma}\" />  \n",
    "  Where:\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?\\mu\" title=\" \\mu\" />: Batch mean.\n",
    "  - <img src=\"https://latex.codecogs.com/svg.image?\\sigma\" title=\" \\sigma\" />: Batch standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61678fc5",
   "metadata": {
    "id": "9ODWIe2yxIsx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 1. Adjust Hyperparameters\n",
    "Add dropout layers and adjust learning rate with a scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56c9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:22:36.581661Z",
     "iopub.status.busy": "2024-12-03T12:22:36.580782Z",
     "iopub.status.idle": "2024-12-03T12:22:36.730295Z",
     "shell.execute_reply": "2024-12-03T12:22:36.729438Z",
     "shell.execute_reply.started": "2024-12-03T12:22:36.581625Z"
    },
    "id": "6QZV-XQixIsy",
    "outputId": "6d616514-4e8b-4563-9cb9-39309d7a78cd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    return lr * decay_rate\n",
    "\n",
    "# Update CNN model with Dropout and Batch Normalization\n",
    "def build_optimized_cnn_model(input_shape=(224, 224, 3), num_classes=3):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # Convolutional Layer 3\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # Flatten and Fully Connected Layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "optimized_cnn_model = build_optimized_cnn_model()\n",
    "optimized_cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a157d3",
   "metadata": {
    "id": "6kaut2xqxIsy",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 2. Train with Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94e26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:22:40.925912Z",
     "iopub.status.busy": "2024-12-03T12:22:40.925288Z",
     "iopub.status.idle": "2024-12-03T12:24:51.555182Z",
     "shell.execute_reply": "2024-12-03T12:24:51.554459Z",
     "shell.execute_reply.started": "2024-12-03T12:22:40.925852Z"
    },
    "id": "vqlFAi8RxIsz",
    "outputId": "ec3c78f7-8911-4c74-9f3e-39bd180c5325",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with a learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = optimized_cnn_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c12c9",
   "metadata": {
    "id": "RvOSEVisxIs0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 3. Transfer Learning\n",
    "Leverage a pre-trained model for improved performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661f148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:19:50.959961Z",
     "iopub.status.busy": "2024-12-03T12:19:50.959388Z",
     "iopub.status.idle": "2024-12-03T12:21:09.251166Z",
     "shell.execute_reply": "2024-12-03T12:21:09.250406Z",
     "shell.execute_reply.started": "2024-12-03T12:19:50.959909Z"
    },
    "id": "RxPIv-9_xIs1",
    "outputId": "234cba93-65a8-4ded-9e2c-9c1da1535fbb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "# Add custom layers for your dataset\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Define the fine-tuned model\n",
    "transfer_learning_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "transfer_learning_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = transfer_learning_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567c832",
   "metadata": {
    "id": "Qe0xUxtExIs2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Monitor Performance\n",
    "Plot Training and Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acfb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:09.252519Z",
     "iopub.status.busy": "2024-12-03T12:21:09.252267Z",
     "iopub.status.idle": "2024-12-03T12:21:09.488680Z",
     "shell.execute_reply": "2024-12-03T12:21:09.487908Z",
     "shell.execute_reply.started": "2024-12-03T12:21:09.252494Z"
    },
    "id": "_J_9sZMNxIs2",
    "outputId": "1fb7dcf5-479b-4981-ca88-a4483458a362",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239d3d0",
   "metadata": {
    "id": "JKIEMc_BxIs3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Improvements**\n",
    "\n",
    "1. **Dropout**:\n",
    "   - Regularizes the model to prevent overfitting:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?\\tilde{x}_i&space;=&space;\\begin{cases}0,&space;&\\text{with&space;probability}&space;p_\\text{drop}\\\\&space;\\frac{x_i}{1-p_\\text{drop}},&space;&\\text{otherwise}\\end{cases}\" title=\" \\tilde{x}_i = \\begin{cases}0, & \\text{with probability} p_\\text{drop}\\\\ \\frac{x_i}{1-p_\\text{drop}}, & \\text{otherwise}\\end{cases}\" />\n",
    "\n",
    "2. **Learning Rate Adjustment**:\n",
    "   - Dynamically reduces learning rate for better convergence:\n",
    "     <img src=\"https://latex.codecogs.com/svg.image?\\eta_t&space;=&space;\\eta_0&space;\\cdot&space;\\gamma^t\" title=\" \\eta_t = \\eta_0 \\cdot \\gamma^t\" />\n",
    "\n",
    "3. **Transfer Learning**:\n",
    "   - Leverages pre-trained knowledge while adapting to your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724e7cb",
   "metadata": {
    "id": "9OMNEQcNxIs4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 11. **Save Model**: Save the trained model in HDF5 format for future use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c58bc3",
   "metadata": {
    "id": "6bU5MFHzxIs4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **1. Save the Trained Model**\n",
    "\n",
    "You can save the trained model in HDF5 format using the `save` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c6a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:09.493343Z",
     "iopub.status.busy": "2024-12-03T12:21:09.493067Z",
     "iopub.status.idle": "2024-12-03T12:21:09.712888Z",
     "shell.execute_reply": "2024-12-03T12:21:09.711959Z",
     "shell.execute_reply.started": "2024-12-03T12:21:09.493319Z"
    },
    "id": "DKEFnNblxIs5",
    "outputId": "abbdbfe1-580f-408a-c237-cc28721b1312",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = \"optimized_cnn_model.h5\"\n",
    "optimized_cnn_model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c3bfb",
   "metadata": {
    "id": "qAMcSqJjxIs6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **2. Load the Saved Model**\n",
    "\n",
    "Later, you can reload the model using `load_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c9f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:09.714173Z",
     "iopub.status.busy": "2024-12-03T12:21:09.713877Z",
     "iopub.status.idle": "2024-12-03T12:21:09.981995Z",
     "shell.execute_reply": "2024-12-03T12:21:09.981165Z",
     "shell.execute_reply.started": "2024-12-03T12:21:09.714147Z"
    },
    "id": "nH-bRsJuxIs6",
    "outputId": "a7c6ecde-ee59-4adc-9064-1adcec98eb45",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Verify the model by displaying the architecture\n",
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b9dd6",
   "metadata": {
    "id": "hmHl1HHfxIs7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Why Use HDF5 Format?**\n",
    "\n",
    "1. **Portability**: The HDF5 format is widely supported and allows easy sharing across environments.\n",
    "2. **Metadata**: Saves both the model architecture and weights in a single file.\n",
    "3. **Future Use**: You can reload the model for further training or inference without redefining its architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd538ea3",
   "metadata": {
    "id": "albV38bwxIs8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 12. **Build Prediction Pipeline**: Create a function to preprocess new images and make predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514543fa",
   "metadata": {
    "id": "VoGPwZjcxIs8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Step 1: Preprocessing Function**\n",
    "\n",
    "Create a function to preprocess a single image before passing it to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178d8f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:09.983351Z",
     "iopub.status.busy": "2024-12-03T12:21:09.983063Z",
     "iopub.status.idle": "2024-12-03T12:21:09.989869Z",
     "shell.execute_reply": "2024-12-03T12:21:09.989219Z",
     "shell.execute_reply.started": "2024-12-03T12:21:09.983324Z"
    },
    "id": "u7NfDYhGxIs9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocesses an image for model prediction.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        target_size (tuple): Target size for resizing the image (height, width).\n",
    "\n",
    "    Returns:\n",
    "        np.array: Preprocessed image ready for prediction.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    # Convert the image to an array\n",
    "    image_array = img_to_array(image)\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    image_array = image_array / 255.0\n",
    "    # Add batch dimension\n",
    "    image_array = tf.expand_dims(image_array, axis=0)\n",
    "    return image_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90409e",
   "metadata": {
    "id": "OKWEH5dexIs9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Step 2: Prediction Function**\n",
    "\n",
    "Create a function to predict the class of a new image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bde421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:09.991283Z",
     "iopub.status.busy": "2024-12-03T12:21:09.990934Z",
     "iopub.status.idle": "2024-12-03T12:21:10.008936Z",
     "shell.execute_reply": "2024-12-03T12:21:10.008084Z",
     "shell.execute_reply.started": "2024-12-03T12:21:09.991247Z"
    },
    "id": "Y5gLTy8mxIs-",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, class_names=['Cat', 'Dog', 'Horse']):\n",
    "    \"\"\"\n",
    "    Predicts the class of a given image using the trained model.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model (tf.keras.Model): Trained model for prediction.\n",
    "        class_names (list): List of class names.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted class name.\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    # Predict probabilities\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = tf.argmax(predictions[0]).numpy()\n",
    "    # Get the class name\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062be6fe",
   "metadata": {
    "id": "rgdluX24xIs-",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Step 3: Example Usage**\n",
    "\n",
    "Load your trained model and make predictions on new images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a7f70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:10.010434Z",
     "iopub.status.busy": "2024-12-03T12:21:10.010102Z",
     "iopub.status.idle": "2024-12-03T12:21:10.866968Z",
     "shell.execute_reply": "2024-12-03T12:21:10.866070Z",
     "shell.execute_reply.started": "2024-12-03T12:21:10.010398Z"
    },
    "id": "USOUOKlmxIs_",
    "outputId": "9eec0367-cc66-4d81-c441-4bb5a6faf152",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = \"optimized_cnn_model.h5\"\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Predict a new image\n",
    "image_path = \"/kaggle/input/animal/Dataset/test/horse/horse-arabs-stallion-ride-53114.jpeg\"\n",
    "predicted_class = predict_image(image_path, loaded_model)\n",
    "print(f\"The predicted class is: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c3341",
   "metadata": {
    "id": "Zcz2sOpCxIs_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. **Preprocessing**:\n",
    "   - Images are resized, normalized, and prepared with a batch dimension.\n",
    "2. **Prediction**:\n",
    "   - The model outputs class probabilities, and the class with the highest probability is selected as the predicted class.\n",
    "3. **Class Names**:\n",
    "   - Ensure the `class_names` list matches the order of labels used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7075b5b",
   "metadata": {
    "id": "IM-fgRvjxItA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 13. **Develop Deployment App**: Build a web app using Streamlit or Flask for users to upload and classify images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e252f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:21:10.868693Z",
     "iopub.status.busy": "2024-12-03T12:21:10.868399Z",
     "iopub.status.idle": "2024-12-03T12:21:17.014527Z",
     "shell.execute_reply": "2024-12-03T12:21:17.013741Z",
     "shell.execute_reply.started": "2024-12-03T12:21:10.868665Z"
    },
    "id": "bCrYAYJWxItA",
    "outputId": "b16c0a67-f74a-42b8-a005-b7a9ebfaafbd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Load the trained model\n",
    "MODEL_PATH = \"/kaggle/working/optimized_cnn_model.h5\"  # Replace with your model path\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Define class names\n",
    "CLASS_NAMES = ['Cat', 'Dog', 'Horse']\n",
    "\n",
    "# HTML and CSS for an awesome design\n",
    "html_code = \"\"\"\n",
    "<style>\n",
    "    .container {\n",
    "        font-family: Arial, sans-serif;\n",
    "        text-align: center;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    .banner {\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    .upload-btn {\n",
    "        display: inline-block;\n",
    "        background-color: #1E88E5;\n",
    "        color: white;\n",
    "        border: none;\n",
    "        border-radius: 5px;\n",
    "        padding: 15px 30px;\n",
    "        font-size: 16px;\n",
    "        cursor: pointer;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "    .upload-btn:hover {\n",
    "        background-color: #1565C0;\n",
    "    }\n",
    "    .result {\n",
    "        background-color: #e3f2fd;\n",
    "        color: #333;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "        margin-top: 30px;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "    .image-preview {\n",
    "        margin: 20px auto;\n",
    "        border: 2px solid #ddd;\n",
    "        border-radius: 10px;\n",
    "        padding: 10px;\n",
    "        max-width: 300px;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div class=\"container banner\">\n",
    "    <h1>Welcome to the Animal Classifier</h1>\n",
    "    <p>Upload an image of a Cat, Dog, or Horse to classify it!</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_code))\n",
    "\n",
    "# Define the directory where images are stored (uploaded via \"Add Data\")\n",
    "IMAGE_DIR = \"/kaggle/input/animal/Dataset/test/horse/\"  # Replace with your folder path\n",
    "\n",
    "# Display available images\n",
    "images = os.listdir(IMAGE_DIR)\n",
    "if not images:\n",
    "    print(\"No images found in the directory.\")\n",
    "else:\n",
    "    print(\"Available images:\")\n",
    "    for idx, image_name in enumerate(images, start=1):\n",
    "        print(f\"{idx}. {image_name}\")\n",
    "\n",
    "    # Ask the user to select an image by its index\n",
    "    selected_index = int(input(\"Enter the number of the image you want to classify: \")) - 1\n",
    "    if selected_index < 0 or selected_index >= len(images):\n",
    "        print(\"Invalid selection. Please run the cell again.\")\n",
    "    else:\n",
    "        selected_image_path = os.path.join(IMAGE_DIR, images[selected_index])\n",
    "\n",
    "        # Display the selected image\n",
    "        selected_image = Image.open(selected_image_path)\n",
    "        display(HTML('<h3 style=\"text-align:center;\">Selected Image</h3>'))\n",
    "        display(selected_image)\n",
    "\n",
    "        # Preprocess the image\n",
    "        def preprocess_image(image, target_size=(224, 224)):\n",
    "            \"\"\"\n",
    "            Preprocess the uploaded image for model prediction.\n",
    "            Args:\n",
    "                image (PIL.Image): Input image.\n",
    "                target_size (tuple): Target size for resizing.\n",
    "            Returns:\n",
    "                np.array: Preprocessed image ready for prediction.\n",
    "            \"\"\"\n",
    "            image = image.resize(target_size)  # Resize the image\n",
    "            image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "            image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "            return image_array\n",
    "\n",
    "        preprocessed_image = preprocess_image(selected_image)\n",
    "\n",
    "        # Make a prediction\n",
    "        predictions = model.predict(preprocessed_image)\n",
    "        predicted_class_index = np.argmax(predictions[0])\n",
    "        predicted_class = CLASS_NAMES[predicted_class_index]\n",
    "        confidence_score = predictions[0][predicted_class_index] * 100  # Convert to percentage\n",
    "\n",
    "        # Display Prediction Result\n",
    "        result_html = f\"\"\"\n",
    "        <div class=\"container result\">\n",
    "            <h3>Classification Result</h3>\n",
    "            <p><strong>Predicted Class:</strong> {predicted_class}</p>\n",
    "            <p><strong>Confidence Score:</strong> {confidence_score:.2f}%</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(result_html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378e1d2",
   "metadata": {
    "id": "QEuEoZJaxItB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Step 4: App Features**\n",
    "\n",
    "1. **Upload Image**:\n",
    "   - Users can upload an image file (JPG, JPEG, PNG).\n",
    "2. **Display Uploaded Image**:\n",
    "   - The uploaded image is displayed for confirmation.\n",
    "3. **Predict Class**:\n",
    "   - The model classifies the image as Cat, Dog, or Horse, and the result is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747a196",
   "metadata": {
    "id": "UfDF-n7AxItC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### **Step 5: Deployment (Optional)**\n",
    "\n",
    "To deploy the app, you can use platforms like **Streamlit Cloud**, **Heroku**, or **AWS**. For Streamlit Cloud:\n",
    "1. Push your code to a GitHub repository.\n",
    "2. Connect your repository to Streamlit Cloud.\n",
    "3. Deploy the app with one click."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca6d28",
   "metadata": {
    "id": "2WiU3TLHxItC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 14. **Test Deployment**: Validate the app with various image inputs to ensure functionality.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfac9de",
   "metadata": {
    "id": "TOd6UfUXxItD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 15. **Document & Present**: Prepare a report with project details, results, and upload code to a repository (e.g., GitHub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c88e9f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "xr3fPf1txItD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6197205,
     "sourceId": 10057073,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.635609,
   "end_time": "2024-12-03T18:35:57.008244",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-03T18:35:40.372635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
